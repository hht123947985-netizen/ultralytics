"""
æ‰¹é‡è®­ç»ƒæ‰€æœ‰benchmarkæ¨¡å‹ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
- è·³è¿‡å·²æœ‰è®­ç»ƒç»“æœ
- ç»Ÿä¸€ä½¿ç”¨runs/detect/benchmarkç›®å½•
"""
import yaml
from pathlib import Path
from ultralytics import YOLO
import torch

# è§£å†³æ˜¾å­˜ä¸è¶³çš„å…³é”®é…ç½®
torch.backends.cudnn.benchmark = False  # ç¦ç”¨è‡ªåŠ¨å¯»æ‰¾æœ€ä½³ç®—æ³•ï¼Œé˜²æ­¢æ˜¾å­˜å³°å€¼æº¢å‡º
torch.backends.cudnn.deterministic = False
torch.backends.cuda.matmul.allow_tf32 = True  # å…è®¸ TF32ï¼Œèƒ½åŠ é€Ÿä¸”çœæ˜¾å­˜

def load_config(config_path='../configs/benchmark_config.yaml'):
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = Path(__file__).parent / config_path
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)

def train_model(model_name, model_config, config, dataset_config):
    """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
    print(f"\n{'='*60}")
    print(f"æ¨¡å‹: {model_name}")
    print(f"{'='*60}")

    # æ£€æŸ¥æ˜¯å¦å·²æœ‰è®­ç»ƒç»“æœ
    if 'existing_results' in model_config:
        existing_path = Path(model_config['existing_results'])
        if existing_path.exists():
            print(f"âœ… å‘ç°å·²æœ‰è®­ç»ƒç»“æœ: {existing_path}")
            print(f"â­ï¸  è·³è¿‡è®­ç»ƒï¼Œå°†ä½¿ç”¨ç°æœ‰ç»“æœè¿›è¡Œè¯„ä¼°")
            return {'status': 'existing', 'path': existing_path}

    # åˆå§‹åŒ–æ¨¡å‹
    print(f"ğŸ“¦ åŠ è½½æ¨¡å‹: {model_config['model']}")
    model = YOLO(model_config['model'])

    # è®¾ç½®è®­ç»ƒå‚æ•° - å•ç‹¬è¯»å–æ¯ä¸ªå‚æ•°
    train_args = {
        'data': dataset_config['path'],
        'name': model_config.get('name', model_name),
        'optimizer': model_config.get('optimizer', 'auto'),
        'lr0': model_config.get('lr0', 0.01),
        'epochs': model_config.get('epochs', config.get('train', {}).get('epochs', 100)),
        'imgsz': model_config.get('imgsz', config.get('train', {}).get('imgsz', 640)),
        'batch': model_config.get('batch', config.get('train', {}).get('batch', 16)),
        'device': model_config.get('device', config.get('train', {}).get('device', '0')),
        'workers': model_config.get('workers', config.get('train', {}).get('workers', 8)),
        'patience': model_config.get('patience', config.get('train', {}).get('patience', 50)),
        'project': model_config.get('project', config.get('train', {}).get('project', 'runs/detect')),
        'save': model_config.get('save', config.get('train', {}).get('save', True)),
        'plots': model_config.get('plots', config.get('train', {}).get('plots', True)),
    }

    # å¼€å§‹è®­ç»ƒ
    try:
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒ...")
        results = model.train(**train_args)
        save_dir = Path(results.save_dir)
        print(f"\nâœ… {model_name} è®­ç»ƒå®Œæˆ!")
        print(f"ğŸ“‚ ç»“æœä¿å­˜åœ¨: {save_dir}")
        return {'status': 'trained', 'path': save_dir, 'results': results}
    except Exception as e:
        print(f"\nâŒ {model_name} è®­ç»ƒå¤±è´¥: {str(e)}")
        return {'status': 'failed', 'error': str(e)}

def main():
    """ä¸»å‡½æ•°"""
    # åŠ è½½é…ç½®
    config = load_config()

    if not config:
        print("âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥")
        return

    # æ£€æŸ¥GPU
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"\n{'='*60}")
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    if device == 'cuda':
        print(f"ğŸ® GPU: {torch.cuda.get_device_name(0)}")
    print(f"{'='*60}")

    # æ›´æ–°è®¾å¤‡é…ç½®
    if 'train' not in config:
        config['train'] = {}
    config['train']['device'] = device

    # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
    results = {}
    for model_name, model_config in config['models'].items():
        result = train_model(
            model_name=model_name,
            model_config=model_config,
            config=config,
            dataset_config=config['dataset']
        )
        results[model_name] = result

    # æ‰“å°æ±‡æ€»
    print("\n" + "="*60)
    print("ğŸ“Š è®­ç»ƒæ±‡æ€»")
    print("="*60)

    for model_name, result in results.items():
        status = result['status']
        if status == 'existing':
            print(f"âœ… {model_name:15s} - ä½¿ç”¨ç°æœ‰ç»“æœ")
        elif status == 'trained':
            print(f"ğŸ‰ {model_name:15s} - æ–°è®­ç»ƒå®Œæˆ")
        elif status == 'failed':
            print(f"âŒ {model_name:15s} - å¤±è´¥: {result['error']}")

    print("\nä¸‹ä¸€æ­¥: è¿è¡Œ 'python eval_all.py' è¿›è¡Œè¯„ä¼°å¯¹æ¯”")

if __name__ == '__main__':
    main()
