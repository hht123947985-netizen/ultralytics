"""
Faster R-CNN è®­ç»ƒè„šæœ¬ (åŸºäº Detectron2)
ç‹¬ç«‹äº Ultralytics æ¡†æ¶è¿è¡Œ

æ˜¾å­˜ä¼˜åŒ–é…ç½® (é’ˆå¯¹12GB GPU):
- Batch size: 1 (Faster R-CNN æ˜¾å­˜å ç”¨è¿œå¤§äº YOLO)
- ROI batch size: 64 (é»˜è®¤512, å¤§å¹…é™ä½)
- æ¢¯åº¦ç´¯ç§¯: 4 steps (ç­‰æ•ˆ batch_size=4)
- Image size: 960x960 (ä¸å…¶ä»–æ¨¡å‹ä¸€è‡´)

å¯¹æ¯”å…¶ä»–æ¨¡å‹é…ç½®:
- YOLO11s/YOLOv8s: batch=16, imgsz=960
- RT-DETR-L: batch=4, imgsz=960
- Faster R-CNN: batch=1 (å®é™…ç­‰æ•ˆ4), imgsz=960
"""
import os
import yaml
import torch
import json
from pathlib import Path
from datetime import datetime

def check_dependencies():
    """æ£€æŸ¥å¹¶å®‰è£…å¿…è¦ä¾èµ–"""
    try:
        import detectron2
        print("âœ… Detectron2 å·²å®‰è£…")
    except ImportError:
        print("âŒ æœªæ£€æµ‹åˆ° Detectron2")
        print("\nè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…:")
        print("pip install 'git+https://github.com/facebookresearch/detectron2.git'")
        print("\næˆ–ä½¿ç”¨é¢„ç¼–è¯‘ç‰ˆæœ¬:")
        print("python -m pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu118/torch2.0/index.html")
        return False

    try:
        from detectron2.config import get_cfg
        from detectron2.engine import DefaultTrainer
        from detectron2.data import DatasetCatalog, MetadataCatalog
        from detectron2 import model_zoo
        print("âœ… Detectron2 å¯¼å…¥æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ Detectron2 å¯¼å…¥å¤±è´¥: {e}")
        return False

def convert_yolo_to_coco(dataset_yaml_path):
    """
    å°† YOLO æ ¼å¼æ•°æ®é›†è½¬æ¢ä¸º COCO æ ¼å¼

    Args:
        dataset_yaml_path: YOLO æ•°æ®é›†çš„ yaml æ–‡ä»¶è·¯å¾„

    Returns:
        train_json, val_json: COCO æ ¼å¼çš„æ ‡æ³¨æ–‡ä»¶è·¯å¾„
    """
    from detectron2.structures import BoxMode
    from detectron2.data import DatasetCatalog, MetadataCatalog
    import cv2

    # è¯»å– YOLO æ•°æ®é›†é…ç½®
    with open(dataset_yaml_path, 'r') as f:
        dataset_config = yaml.safe_load(f)

    dataset_root = Path(dataset_yaml_path).parent
    train_img_dir = dataset_root / dataset_config.get('train', 'images/train')
    val_img_dir = dataset_root / dataset_config.get('val', 'images/val')

    train_label_dir = str(train_img_dir).replace('images', 'labels')
    val_label_dir = str(val_img_dir).replace('images', 'labels')

    def yolo_to_coco_dict(img_dir, label_dir, class_names):
        """è½¬æ¢å•ä¸ªæ•°æ®é›†åˆ†å‰²"""
        dataset_dicts = []
        img_dir = Path(img_dir)
        label_dir = Path(label_dir)

        for idx, img_path in enumerate(img_dir.glob('*.jpg')):
            record = {}

            # è¯»å–å›¾åƒå°ºå¯¸
            img = cv2.imread(str(img_path))
            height, width = img.shape[:2]

            record["file_name"] = str(img_path)
            record["image_id"] = idx
            record["height"] = height
            record["width"] = width

            # è¯»å–æ ‡æ³¨
            label_path = label_dir / f"{img_path.stem}.txt"
            objs = []

            if label_path.exists():
                with open(label_path, 'r') as f:
                    for line in f:
                        parts = line.strip().split()
                        if len(parts) != 5:
                            continue

                        class_id, x_center, y_center, w, h = map(float, parts)

                        # YOLO æ ¼å¼ (å½’ä¸€åŒ–) è½¬ COCO æ ¼å¼ (ç»å¯¹åæ ‡)
                        x_center *= width
                        y_center *= height
                        w *= width
                        h *= height

                        x_min = x_center - w / 2
                        y_min = y_center - h / 2

                        obj = {
                            "bbox": [x_min, y_min, w, h],
                            "bbox_mode": BoxMode.XYWH_ABS,
                            "category_id": int(class_id),
                        }
                        objs.append(obj)

            record["annotations"] = objs
            dataset_dicts.append(record)

        return dataset_dicts

    # æ³¨å†Œæ•°æ®é›†
    class_names = dataset_config.get('names', [])

    train_dicts = yolo_to_coco_dict(train_img_dir, train_label_dir, class_names)
    val_dicts = yolo_to_coco_dict(val_img_dir, val_label_dir, class_names)

    # æ³¨å†Œåˆ° Detectron2
    DatasetCatalog.register("wind_turbine_train", lambda: train_dicts)
    MetadataCatalog.get("wind_turbine_train").set(thing_classes=class_names)

    DatasetCatalog.register("wind_turbine_val", lambda: val_dicts)
    MetadataCatalog.get("wind_turbine_val").set(thing_classes=class_names)

    print(f"âœ… æ•°æ®é›†è½¬æ¢å®Œæˆ:")
    print(f"   è®­ç»ƒé›†: {len(train_dicts)} å¼ å›¾åƒ")
    print(f"   éªŒè¯é›†: {len(val_dicts)} å¼ å›¾åƒ")
    print(f"   ç±»åˆ«æ•°: {len(class_names)} - {class_names}")

    return "wind_turbine_train", "wind_turbine_val", len(class_names)

def setup_faster_rcnn_config(num_classes, output_dir, config_yaml):
    """é…ç½® Faster R-CNN"""
    from detectron2.config import get_cfg
    from detectron2 import model_zoo

    cfg = get_cfg()

    # åŸºç¡€æ¨¡å‹é…ç½®
    cfg.merge_from_file(model_zoo.get_config_file(
        "COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml"
    ))

    # æ•°æ®é›†é…ç½®
    cfg.DATASETS.TRAIN = ("wind_turbine_train",)
    cfg.DATASETS.TEST = ("wind_turbine_val",)
    cfg.DATALOADER.NUM_WORKERS = config_yaml['train'].get('workers', 0)

    # æ¨¡å‹é…ç½®
    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(
        "COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml"
    )
    cfg.MODEL.ROI_HEADS.NUM_CLASSES = num_classes
    # é™ä½ ROI batch size ä»¥å‡å°‘æ˜¾å­˜å ç”¨ (é»˜è®¤512, é™è‡³64)
    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64
    cfg.MODEL.DEVICE = f"cuda:{config_yaml['train'].get('device', '0')}" if torch.cuda.is_available() else "cpu"

    # è®­ç»ƒé…ç½® - é’ˆå¯¹12GBæ˜¾å­˜ä¼˜åŒ–
    # Faster R-CNN æ˜¾å­˜å ç”¨å¤§ï¼Œbatch size è®¾ä¸º 1
    cfg.SOLVER.IMS_PER_BATCH = 1
    # è°ƒæ•´å­¦ä¹ ç‡ä»¥é€‚åº”å° batch size (åŸå§‹ 0.00025 å¯¹åº” batch=2)
    cfg.SOLVER.BASE_LR = 0.000125
    # è®¡ç®—æ€»è¿­ä»£æ¬¡æ•°ï¼šepochs * (æ•°æ®é›†å¤§å° / batch_size)
    # ç²—ç•¥ä¼°ç®—: 200 epochs * 150 images / 1 = 30000 iterations
    cfg.SOLVER.MAX_ITER = 30000
    cfg.SOLVER.STEPS = []  # ä¸ä½¿ç”¨å­¦ä¹ ç‡è¡°å‡
    cfg.SOLVER.GAMMA = 0.1
    cfg.SOLVER.CHECKPOINT_PERIOD = 5000
    # æ¢¯åº¦ç´¯ç§¯ï¼Œæ¨¡æ‹Ÿæ›´å¤§çš„ batch size
    cfg.SOLVER.GRADIENT_ACCUMULATION_STEPS = 4  # ç­‰æ•ˆ batch_size=4

    # è¾“å…¥å›¾åƒå°ºå¯¸ - ä¸å…¶ä»–æ¨¡å‹ä¿æŒä¸€è‡´
    cfg.INPUT.MIN_SIZE_TRAIN = (config_yaml['train'].get('imgsz', 960),)
    cfg.INPUT.MAX_SIZE_TRAIN = config_yaml['train'].get('imgsz', 960)
    cfg.INPUT.MIN_SIZE_TEST = config_yaml['train'].get('imgsz', 960)
    cfg.INPUT.MAX_SIZE_TEST = config_yaml['train'].get('imgsz', 960)

    # è¾“å‡ºé…ç½®
    cfg.OUTPUT_DIR = str(output_dir)
    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)

    # æ‰“å°é…ç½®æ‘˜è¦
    print("\n" + "="*60)
    print("ğŸ“‹ Faster R-CNN é…ç½®æ‘˜è¦")
    print("="*60)
    print(f"å›¾åƒå°ºå¯¸: {cfg.INPUT.MIN_SIZE_TRAIN[0]}x{cfg.INPUT.MAX_SIZE_TRAIN}")
    print(f"Batch size: {cfg.SOLVER.IMS_PER_BATCH}")
    print(f"æ¢¯åº¦ç´¯ç§¯: {cfg.SOLVER.GRADIENT_ACCUMULATION_STEPS} steps (ç­‰æ•ˆ batch={cfg.SOLVER.IMS_PER_BATCH * cfg.SOLVER.GRADIENT_ACCUMULATION_STEPS})")
    print(f"ROI batch size: {cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE}")
    print(f"å­¦ä¹ ç‡: {cfg.SOLVER.BASE_LR}")
    print(f"æœ€å¤§è¿­ä»£: {cfg.SOLVER.MAX_ITER}")
    print(f"ç±»åˆ«æ•°: {num_classes}")
    print(f"è®¾å¤‡: {cfg.MODEL.DEVICE}")
    print("="*60 + "\n")

    return cfg

def train_faster_rcnn():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    from detectron2.engine import DefaultTrainer
    from detectron2.evaluation import COCOEvaluator

    print("="*60)
    print("ğŸš€ Faster R-CNN è®­ç»ƒ")
    print("="*60)

    # 0. æ¸…ç† GPU æ˜¾å­˜
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        print(f"ğŸ”§ GPU æ˜¾å­˜æ¸…ç†å®Œæˆ")
        print(f"   GPU: {torch.cuda.get_device_name(0)}")
        print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")

    # 1. æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        return

    # 2. åŠ è½½é…ç½®
    config_path = Path(__file__).parent.parent / 'configs' / 'benchmark_config.yaml'
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)

    # 3. è½¬æ¢æ•°æ®é›†
    dataset_yaml = Path('/home/aiuser/work/ultralytics') / config['dataset']['path']
    train_name, val_name, num_classes = convert_yolo_to_coco(dataset_yaml)

    # 4. è®¾ç½®è¾“å‡ºç›®å½•
    output_dir = Path('/home/aiuser/work/ultralytics/runs/detect/benchmark/faster_rcnn')
    output_dir.mkdir(parents=True, exist_ok=True)

    # 5. é…ç½®æ¨¡å‹
    cfg = setup_faster_rcnn_config(num_classes, output_dir, config)

    # 6. è®­ç»ƒ
    print("\n" + "="*60)
    print("å¼€å§‹è®­ç»ƒ...")
    print("="*60)

    class CustomTrainer(DefaultTrainer):
        @classmethod
        def build_evaluator(cls, cfg, dataset_name):
            return COCOEvaluator(dataset_name, cfg, False, output_dir=cfg.OUTPUT_DIR)

    trainer = CustomTrainer(cfg)
    trainer.resume_or_load(resume=False)
    trainer.train()

    print("\n" + "="*60)
    print("âœ… Faster R-CNN è®­ç»ƒå®Œæˆ!")
    print(f"ğŸ“‚ æ¨¡å‹ä¿å­˜åœ¨: {output_dir}")
    print("="*60)

    # ä¿å­˜é…ç½®ä¿¡æ¯
    info = {
        'model': 'Faster R-CNN (ResNet50-FPN)',
        'framework': 'Detectron2',
        'num_classes': num_classes,
        'output_dir': str(output_dir),
        'trained_at': datetime.now().isoformat()
    }

    with open(output_dir / 'model_info.json', 'w') as f:
        json.dump(info, f, indent=2)

if __name__ == '__main__':
    train_faster_rcnn()
